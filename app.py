import os
from typing import Literal

import streamlit as st
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

# .envèª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç”¨ï¼‰
load_dotenv()

# Secretsï¼ˆStreamlit Cloudç”¨ï¼‰ã‚‚è€ƒæ…®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    try:
        OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", None)
    except Exception:
        OPENAI_API_KEY = None

def call_llm(user_text: str, expert: Literal["ãƒãƒ¼ã‚±æˆ¦ç•¥å®¶", "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢è¨­è¨ˆè€…"]) -> str:
    system_messages = {
        "ãƒãƒ¼ã‚±æˆ¦ç•¥å®¶": (
            "ã‚ãªãŸã¯å³å¯†ãªãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³æ€è€ƒã®ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥å®¶ã§ã™ã€‚"
            "å¸‚å ´åˆ†æã€ãƒšãƒ«ã‚½ãƒŠã€4P/3Cã€ãƒ•ã‚¡ãƒãƒ«ã€CAC/LTVã‚’è¸ã¾ãˆã€"
            "å®Ÿè¡Œå¯èƒ½ãªæ‰“ã¡æ‰‹ã‚’è¦‹å‡ºã—ã€æ ¹æ‹ ã‚’ç°¡æ½”ã«æç¤ºã—ã¦ãã ã•ã„ã€‚"
            "æ—¥æœ¬èªã§ã€å…·ä½“ä¾‹ã¨ç°¡å˜ãªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚‚æ·»ãˆã¦ç­”ãˆã¦ãã ã•ã„ã€‚"
        ),
        "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢è¨­è¨ˆè€…": (
            "ã‚ãªãŸã¯å …ç‰¢ã§æ‹¡å¼µå¯èƒ½ãªè¨­è¨ˆã‚’é‡è¦–ã™ã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã§ã™ã€‚"
            "è¦ä»¶ã®åˆ†è§£ã€éæ©Ÿèƒ½è¦ä»¶ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é¸å®šã€ãƒ‡ãƒ¼ã‚¿è¨­è¨ˆã€"
            "ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ˜ç¤ºã—ãªãŒã‚‰ã€æ—¥æœ¬èªã§ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
        ),
    }

    if not OPENAI_API_KEY:
        return (
            "ã€ã‚¨ãƒ©ãƒ¼ã€‘OpenAI APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n"
            "ãƒ­ãƒ¼ã‚«ãƒ«ã¯ .env ã« OPENAI_API_KEY=xxxxx ã‚’è¨­å®šã€\n"
            "Cloudã¯ Settingsâ†’Secrets ã§ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚"
        )

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,
        openai_api_key=OPENAI_API_KEY,
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", "{system_role}"),
            ("human", "ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›:\n{user_text}\n\nä¸Šè¨˜ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"),
        ]
    )

    chain = prompt | llm | StrOutputParser()

    return chain.invoke(
        {"system_role": system_messages[expert], "user_text": user_text.strip()}
    )

st.set_page_config(page_title="Streamlit LLM App (LangChain)", page_icon="ğŸ’¬", layout="centered")
st.title("ğŸ’¬ Streamlit Ã— LangChain Ã— OpenAI : LLMã‚¢ãƒ—ãƒª")

with st.expander("â„¹ï¸ ã“ã®ã‚¢ãƒ—ãƒªã®æ¦‚è¦ã¨ä½¿ã„æ–¹", expanded=True):
    st.markdown(
        """
**æ¦‚è¦**  
- å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’LangChainçµŒç”±ã§OpenAIã«æ¸¡ã—ã€å›ç­”ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚  
- ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ã€Œå°‚é–€å®¶ãƒ­ãƒ¼ãƒ«ã€ã§ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒåˆ‡ã‚Šæ›¿ã‚ã‚Šã¾ã™ã€‚

**ä½¿ã„æ–¹**  
1. å°‚é–€å®¶ãƒ­ãƒ¼ãƒ«ã‚’é¸æŠ  
2. ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›  
3. ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™  
        """
    )

expert = st.radio(
    "å°‚é–€å®¶ãƒ­ãƒ¼ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
    options=("ãƒãƒ¼ã‚±æˆ¦ç•¥å®¶", "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢è¨­è¨ˆè€…"),
    horizontal=True,
)

with st.form("query_form", clear_on_submit=False):
    user_input = st.text_area(
        "å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ",
        placeholder="ä¾‹ï¼‰ECã‚µã‚¤ãƒˆã®æ–°è¦é¡§å®¢ç²å¾—ã‚’æœˆ100äººã«å¢—ã‚„ã—ãŸã„ã€‚ç¾çŠ¶ã¯SNSæµå…¥ã®ã¿ã§ã™ã€‚",
        height=150,
    )
    submitted = st.form_submit_button("é€ä¿¡")

if submitted:
    if not user_input.strip():
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("LLMãŒè€ƒãˆã¦ã„ã¾ã™â€¦"):
            answer = call_llm(user_input, expert)
        st.subheader("å›ç­”")
        st.write(answer)

st.caption("â€» APIã‚­ãƒ¼ã¯GitHubã«ã‚³ãƒŸãƒƒãƒˆã—ãªã„ã§ãã ã•ã„ï¼ˆ.envï¼Secretsã‚’ä½¿ç”¨ï¼‰ã€‚")
